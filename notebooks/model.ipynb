{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "from umap import UMAP\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first objective for a modeling step is to identify positive and negative training examples\n",
    "# 2 sources: reachwell competitors and reachwell clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. limited competitor list based on a review of each competitor's website and press:\n",
    "\n",
    "parent_square = [\n",
    "    \"Oakland Unified School District\",      \"9700000US0628050\",\n",
    "    \"Virginia Beach City Public Schools\",   \"9700000US5103840\",\n",
    "    \"Knox County Schools\",                  \"9700000US4702220\", # (Tennessee)\n",
    "    \"Fort Wayne Community Schools\",         \"9700000US1803630\",\n",
    "    \"Beaverton School District\",            \"9700000US4101920\",\n",
    "    \"Andrews Independent School District\",  \"9700000US4808280\",\n",
    "]\n",
    "\n",
    "bloomz = [\n",
    "    \"Johnston County Public Schools\",               \"9700000US3702370\",\n",
    "    \"Live Oak School District\",                     \"9700000US0622050\",\n",
    "    \"Fort Sam Houston Independent School District\", \"9700000US4820160\",\n",
    "    \"Windsor Unified School District\",              \"9700000US0600034\",\n",
    "    \"Licking Heights Local Schools\",                \"9700000US3904800\",\n",
    "    \"Ozark City Schools\",                           \"9700000US0102640\",\n",
    "    \"Henderson County Public Schools\",              \"9700000US2102710\",\n",
    "    # https://kipptexas.org/ -- these schools are located in Houston, Dallas, San Antonio, Austin\n",
    "    \"KIPP Texas Public Schools\",                    \"9700000US4823640\", # Houston\n",
    "    \"KIPP Texas Public Schools\",                    \"9700000US4816230\", # Dallas\n",
    "    \"KIPP Texas Public Schools\",                    \"9700000US4838730\", # San antonio\n",
    "    \"KIPP Texas Public Schools\",                    \"9700000US4808940\", # Austin\n",
    "    \"North Lawrance Community Schools\",             \"9700000US1807860\",\n",
    "    \"Round Rock Independent School District\",       \"9700000US4838080\",\n",
    "    \"NYC Department of Education\",                  \"9700000US3620580\",\n",
    "    \"Los Angeles Unified School District\",          \"9700000US0622710\"\n",
    "]\n",
    "\n",
    "talking_points = [ \n",
    "    \"Wake County Public Schools\",        \"9700000US3704720\",\n",
    "    \"Boston Public Schools\",             \"9700000US2502790\",\n",
    "    \"Cincinnati Public Schools\",         \"9700000US3904375\",\n",
    "    \"Seattle Public Schools\",            \"9700000US5307710\",\n",
    "    \"Elk Grove Unified School District\", \"9700000US0612330\",\n",
    "    \"Aurora Public Schools\",             \"9700000US3103360\",\n",
    "    \"Tulsa Public Schools\",              \"9700000US4030240\",\n",
    "    \"Pittsburgh Public Schools\",         \"9700000US4024180\"\n",
    "]\n",
    "\n",
    "competitors = []\n",
    "for cname,ids in [ (\"TalkingPoints\",talking_points), (\"Bloomz\", bloomz), (\"ParentSquare\", parent_square) ]:  \n",
    "    competitors += [ \n",
    "        {\"geo_id\":id_, \"uses_competitor\": cname} for id_ in ids[1::2]\n",
    "    ]\n",
    "\n",
    "competitors_df = pd.DataFrame.from_records(competitors)\n",
    "\n",
    "competitors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. reachwell's client list, which was provided to me as a .kml file of coordinate points alongside the client name. I converted these to school district and county \n",
    "# IDs by finding the school district corresponding to each geographic point. fortunately this is implemented in geopandas. see `extract_client_list.ipynb` for details.\n",
    "reachwell_df = pd.read_csv(\"../reachwell-clients-with-counties.csv\")\n",
    "reachwell_df[\"label\"] = 1\n",
    "reachwell_df[\"is_reachwell_partner\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step is acquiring features: \n",
    "# merge indicators with labeled data and transform some features\n",
    "\n",
    "indicators = pd.read_csv(\"../cty-sd-latest-indicators.csv\")\n",
    "indicators = indicators.merge(reachwell_df,how=\"left\",on=\"geo_id\")\n",
    "indicators = indicators.merge(competitors_df,how=\"left\",on=\"geo_id\")\n",
    "\n",
    "indicators.loc[~indicators[\"uses_competitor\"].isna(), \"label\"] = 1\n",
    "\n",
    "indicators[\"uses_competitor\"] = indicators[\"uses_competitor\"].fillna(\"\")\n",
    "indicators[\"label\"] = indicators[\"label\"].fillna(0)\n",
    "indicators[\"is_reachwell_partner\"] = indicators[\"is_reachwell_partner\"].fillna(0)\n",
    "\n",
    "indicators = indicators.dropna().reset_index(drop=True)\n",
    "indicators[\"label\"].value_counts()\n",
    "\n",
    "indicators[\"log_number_households\"] = indicators[\"total_households\"].apply(np.log)\n",
    "indicators[\"log_median_household_income\"] = indicators[\"median_income_households_with_children\"].apply(np.log)\n",
    "indicators[\"state\"] = indicators[\"geo_name\"].apply(lambda s: s.split(\", \")[-1])\n",
    "# neat. now we have a very imbalanced classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, try to better understand this data. particularly, are reachwell clients similar to eachother? what cohorts exists within the data? \n",
    "# do this with dimensionality reduction because there are a lot of variables\n",
    "\n",
    "reducer = UMAP(n_neighbors=9)\n",
    "percent_cols = [\n",
    "       \"pct_limited_english_households\",\"pct_pop_below_poverty_level\",\"pct_speaks_other_than_english\",\"pct_households_with_chilren\",\n",
    "       \"pct_households_receiving_food_stamps\", \"pct_households_with_children_married_family\", \"pct_pop_3+_in_private_school\"\n",
    "]\n",
    "\n",
    "umap_df = pd.DataFrame(\n",
    "       reducer.fit_transform(indicators[percent_cols]),\n",
    "       columns=['UMAP1', 'UMAP2']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat([indicators, umap_df], axis=1)\n",
    "\n",
    "result_df[\"log_total_households\"] = result_df[\"total_households\"].apply(np.log)\n",
    "\n",
    "alt.Chart(result_df).mark_circle(size=75,opacity=0.6,stroke='black',strokeWidth=0.4).encode(\n",
    "    x='UMAP1:Q',\n",
    "    y='UMAP2:Q',\n",
    "    color='label:N',\n",
    "    # size=alt.Size('total_households:Q',legend=None),\n",
    "    tooltip=['geo_id', 'geo_name', 'total_households:Q','pct_limited_english_households','pct_pop_below_poverty_level']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=800\n",
    ").interactive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set up a classification problem using `good` as attributes/features (all 0-1 normalized indicators that are not colinear with eachother, as well as log population size)\n",
    "feature_cols = percent_cols + [\"log_number_households\",\"log_median_household_income\"]\n",
    "\n",
    "# what are good metrics for this learning problem?\n",
    "\n",
    "# precision very important. Recall also important but less so (for example i could return the whole list of scholl districts and counties and\n",
    "# this would yield a recall of 1.0... not so helpful). because this will inevitably be a ranking problem (ordering a list of leads by how \n",
    "# similar they are to existing clients), I can use ranking metrics.\n",
    "# a good selection would be MAP@K (or really just AP b/c only ranking one 'query') as there are multiple true values in the impression list but their order is not important\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, precision_score, accuracy_score, balanced_accuracy_score, recall_score,f1_score, average_precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train__imbalanced, test = train_test_split(indicators, train_size=0.8, random_state=SEED,stratify=indicators[\"label\"]) # retrieve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "negative_samples = 100\n",
    "train = pd.concat([\n",
    "    train__imbalanced[train__imbalanced.label == 1], \n",
    "    train__imbalanced[train__imbalanced.label == 0].sample(n=negative_samples, replace=False, random_state=SEED)\n",
    "]).sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"label\"].value_counts(), train[\"geo_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(clf, df_: pd.DataFrame, k=500): #-> Dict[str,float]:\n",
    "\n",
    "    \n",
    "    # run this on the imbalanced versiosn of train and test set\n",
    "    df = df_.copy(deep=True).reset_index(drop=True)\n",
    "    df[\"prediction\"] = clf.predict(df[feature_cols])\n",
    "    df[\"ranking\"] = clf.predict_proba(df[feature_cols])[:,1]\n",
    "\n",
    "    gt = set(df[df.label==1][\"geo_id\"].tolist())\n",
    "    top_k = set(df.sort_values(by=\"ranking\",ascending=False).head(k)[\"geo_id\"].tolist())\n",
    "    return {\n",
    "        \"balanced_accuracy\":    balanced_accuracy_score(y_true=df[\"label\"],y_pred=df[\"prediction\"]),\n",
    "        \"precision\":            precision_score(y_true=df[\"label\"],y_pred=df[\"prediction\"],zero_division=0),\n",
    "        \"recall\":               recall_score(y_true=df[\"label\"],y_pred=df[\"prediction\"],zero_division=0),\n",
    "        \"f1\":                   f1_score(y_true=df[\"label\"],y_pred=df[\"prediction\"],zero_division=0),\n",
    "\n",
    "        # ranking metrics: web.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "        \"average_precision\": average_precision_score(y_true=df[\"label\"],y_score=df[\"ranking\"]),\n",
    "        \"precision_at_k\":    len(gt & top_k)/k, # what percent of results in the first 500 are relevant\n",
    "        # \"recall_at_k\":       len(gt & top_k)/len(gt) # what percent of results in the first 500 are relevant\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid_lr = {\n",
    "    'penalty': ['l2'],  \n",
    "    'C': [0.001, 0.01, 0.03, 0.1, 1, 10],  \n",
    "    'class_weight': [{0:1,1:3},{0:1,1:1}]\n",
    "}\n",
    "\n",
    "\n",
    "gs_lr = GridSearchCV(\n",
    "    estimator=LogisticRegression(solver=\"liblinear\"),\n",
    "    param_grid=param_grid_lr,\n",
    "    # scoring=make_scorer(accuracy_score),\n",
    "    scoring=make_scorer(precision_score,zero_division=0),\n",
    "    cv=10\n",
    ")\n",
    "gs_lr.fit(train[feature_cols],train[\"label\"])\n",
    "\n",
    "\n",
    "param_grid_knn = {\n",
    "    \"n_neighbors\": [3,5,7,9],\n",
    "    \"weights\": [\"distance\",\"uniform\"]\n",
    "}\n",
    "\n",
    "\n",
    "gs_knn = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    param_grid=param_grid_knn,\n",
    "    # scoring=make_scorer(accuracy_score),\n",
    "    scoring=make_scorer(precision_score,zero_division=0),\n",
    "    cv=10\n",
    ")\n",
    "gs_knn.fit(train[feature_cols],train[\"label\"])\n",
    "\n",
    "param_grid_svc = {\n",
    "    'C': [1],#[0.001, 0.01, 0.03, 0.1, 1, 10],  \n",
    "    \"kernel\":[\"rbf\",\"poly\"],\n",
    "    \"degree\":[2], # [1,2]\n",
    "    \"class_weight\":[\"balanced\",None]\n",
    "}\n",
    "\n",
    "gs_kernel = GridSearchCV(\n",
    "    estimator=SVC(probability=True),\n",
    "    param_grid=param_grid_svc,\n",
    "    scoring=make_scorer(precision_score,zero_division=0),\n",
    "    # scoring=make_scorer(accuracy_score),\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "gs_kernel.fit(train[feature_cols],train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline is a dummy model\n",
    "dummy = GridSearchCV(\n",
    "    estimator=DummyClassifier(),\n",
    "    param_grid={\"strategy\":[\"constant\"],\"constant\":[1]},\n",
    "    # scoring=make_scorer(precision_score,zero_division=0),\n",
    "    scoring=make_scorer(accuracy_score),\n",
    "    cv=10\n",
    ")\n",
    "dummy.fit(train[feature_cols],train[\"label\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(gs_lr.cv_results_).sort_values(\"mean_test_score\", ascending=False)\n",
    "# pd.DataFrame(gs_knn.cv_results_).sort_values(\"mean_test_score\",ascending=False)\n",
    "# pd.DataFrame(d.cv_results_)\n",
    "\n",
    "from itertools import product\n",
    "experiment_results = []\n",
    "for (name,model),dataset in product(\n",
    "        {\"dummy\": dummy, \"logistic regression\": gs_lr, \"k nearest neighors\":gs_knn,\"support vecter machine\":gs_kernel}.items(),\n",
    "        [\"test\"]\n",
    "):\n",
    "    d = {\"model\":name,\"dataset\":dataset}\n",
    "    # print(name,model,dataset)\n",
    "    # break\n",
    "    # prit(model)\n",
    "    r = evaluate_model( model, test if dataset == \"test\" else train__imbalanced,k=500 )\n",
    "\n",
    "    experiment_results.append(d | r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records(experiment_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators[\"prediction\"] = gs_lr.predict_proba(indicators[feature_cols])[:,1]\n",
    "plot_df = indicators[indicators.geo_type == \"CTY\"].copy(deep=True)\n",
    "plot_df[\"id\"] =  plot_df[\"geo_id\"].apply(lambda s: int(s.split(\"US\")[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model weights\n",
    "# sorted(zip(list(list(gs_lr.best_estimator_.coef_[0,:])),feature_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "\n",
    "counties = alt.topo_feature(data.us_10m.url, 'counties')\n",
    "\n",
    "alt.Chart(counties).mark_geoshape().encode(\n",
    "    color=alt.Color('prediction:Q',scale=alt.Scale(scheme=\"inferno\")),\n",
    "    tooltip=[\"geo_name:N\",\"prediction:Q\",\"pct_speaks_other_than_english:Q\",\"median_income_households_with_children:Q\",\"total_households:Q\"]\n",
    ").transform_lookup(\n",
    "    lookup='id',\n",
    "    from_=alt.LookupData(plot_df, 'id', ['prediction','geo_name','pct_speaks_other_than_english',\"median_income_households_with_children\",\"total_households\"])\n",
    ").project(\n",
    "    type='albersUsa'\n",
    ").properties(\n",
    "    width=1200,\n",
    "    height=900\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the df (with predictions) as an excel file\n",
    "indicators.sort_values(by=\"prediction\", ascending=False).to_excel(\"../outputs/school-districts-counties-predictions.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# and the geojson file for plotting out counties with deck.gl and altair\n",
    "gdf_counties = gpd.read_file(\"../data/cty-geo/geojson-counties-fips.json\")\n",
    "\n",
    "\n",
    "cols_for_plot = [\n",
    "    \"geo_id\",\"geo_name\", \"geometry\", \"total_households\", \"total_population_5+\", \"median_income_households_with_children\", \"pct_limited_english_households\", \"uses_competitor\",\n",
    "    \"pct_pop_below_poverty_level\", \"pct_households_with_chilren\", \"pct_speaks_only_english\", \"pct_speaks_other_than_english\",\n",
    "    \"pct_households_receiving_food_stamps\", \"pct_households_with_children_married_family\", \"pct_pop_3+_in_private_school\", \"pct_pop_3+_in_public_school\",\n",
    "]\n",
    "indcators[cols_for_plot].to_csv(\"../outputs/county-plots.csv\",index=Fals)\n",
    "cols_for_private_plot = cols_for_plot + [\"prediction\"]\n",
    "\n",
    "gdf_counties = gdf_counties.merge(indicators[indicators.geo_type == \"CTY\"], left_on=\"GEO_ID\", right_on=\"geo_id\", how=\"inner\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_counties[cols_for_plot].to_file(\"../outputs/county-plots.json\",driver=\"GeoJSON\")\n",
    "gdf_counties[cols_for_private_plot].to_file(\"../outputs/county-plots-private.json\",driver=\"GeoJSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
